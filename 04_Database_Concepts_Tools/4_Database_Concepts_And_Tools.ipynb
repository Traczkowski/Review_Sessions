{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Database concepts/Using Database Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "#### What we want to talk about today is a little bit more about databases. Last time we covered APIs which can be used to gather, clean, and (sometimes) move data, but what is going on within the storage units of our company?\n",
    "\n",
    "- Wanted to open up with some high level questions\n",
    "- Talk about what database-adjacent skillsets may be important for certain roles\n",
    "- Demo a few different database tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level Overview\n",
    "\n",
    "#### How are Databases used?\n",
    "- As you know, they're used to store data within an organization, there are lots of different kinds of databases with several different use-cases. Some are built for speed, others for size, and some may be preferable because they are open-source and can be built on commodity hardware and scaled in a way that will be suitable to the needs of the org.\n",
    "- Although there are plenty of options for Data Warehouses (which are sort of your one-stop shop for enterprise level data storage) which are often closed-off and behind a paywall (Google Cloud Platform, AWS, Azure, etc.), you can still find yourself building up a lot of open-source infrastructure at your company even if one of those is being used, and most of the systems that you'd be programming \"around\" those closed datasources can be built up using open source databases/etl software.\n",
    "- While you will have to pay for compute and storage online for most solutions that don't physically require your team to build a server and have it on a rack near you, a lot of the systems that you will be building and tooling can exist on commodity hardware. You'll probably see that often as a bullet-point in a description when you're reading up on database software.\n",
    "- How well a database is funded in your company will be dependant on how important it is to the infrastructure around it as well as the speed that the data is being consumed/used for analytics.\n",
    "- In short, they store the data, you get it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL vs NoSQL...\n",
    "- If you haven't heard this, prepare to.\n",
    "- SQL refers to a classic relational database here and all of the different derivatives of that. Many, many of the databases that you'll probably encounter store data in a \"sql-like\" way. These are tables with columns that you can join in different ways for different purposes depending on the data needed for a particular analysis. Many more established and enterprise players will have big SQL databases in the company. The primary data-structure here is a table. SQL is a little bit more structured in general and changes could potentially take a little bit more planning than the no-sql equivalents.\n",
    "- https://www.postgresql.org/ \n",
    "- https://cloud.google.com/bigquery\n",
    "- https://www.mysql.com/\n",
    "- https://www.oracle.com/database/technologies/appdev/sql.html\n",
    "- NoSQL generally refers to databases like MongoDB, Redis, and some others that are built up more around \"documents\" or key-value pairs. These documents are less structured datatypes and typically NoSQL databases will be indexed on unique ids. Think about this as a world full of varying JSON-like objects. These are more flexible but can become problematic if left unchecked. If you go from needing \"Username\" and \"Password\", to also needing zip code, you can just create an additional field within a document to capture that data, this can leave to sharded data overtime though! \n",
    "- https://www.mongodb.com/\n",
    "- https://redis.io/\n",
    "- https://aws.amazon.com/dynamodb/\n",
    "- https://www.knowledgenile.com/blogs/redis-vs-mongodb/\n",
    "- There are many, many more distinctions between the two but we'll discuss some of the broad strokes.\n",
    "- https://www.xplenty.com/blog/the-sql-vs-nosql-difference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thinking about where the data is stored...\n",
    "\n",
    "- Depending on the use-case and general \"speed\" that the data is moving, data can be stored either in-memory, or on disk, however, the type of disk that you write it to can still vary.\n",
    "- Due to the litany of computer components available out there and the different ways that different databases tax your system, you'll always see many, many differently performing setups in your lifetime, but generally, you can figure that more space and speed are better.\n",
    "- In-Memory - For some workloads that require very fast seek time and can process hundreds of thousands to millions of records per second, you will want to store that data in-memory in a system like Redis. Think about a massive system that is handling data about where users are located in real-time for a GPS-style app, you need to juggle so many users are per second that you may store those logs in-memory for quick retrieval.\n",
    "- https://en.wikipedia.org/wiki/In-memory_database\n",
    "- On-Disk - For \"colder\" storage, where data will not need to be recalled as quickly or used as many times per second, you may store that data onto disk (as opposed to RAM), but there is still a dividing line there, as there are two readily available types of disks to write to...\n",
    "- SSDs are more modern and can attain much faster seek-times than platter HDDs, but there can be questions about data-integrity in the long-term as too many read and writes can cause premature failure.\n",
    "- HDDs, the hard drives you know and love from years of usage. Bigger, slower, and cheaper than SSDs, but for data that is just going to go sit and be queried for an ad-hoc analysis here and there, there is absolutely no issues with using spinning disks.\n",
    "- Distributed Data? - Sometimes, even if you're using a SQL-like language to interact with the data, it is being stored in a way that is different than you may think about local disk storage, rather than sitting on one hard drive on one computer, databases can be distributed over several machines, drives, etc. There is a popular framework built on top of HDFS that is used often out in the field (https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html), we'll cover this more later in the cohort. Also, tools for virtualization (such as docker https://www.docker.com/why-docker) have also made the distribution of data and systems easier in more recent years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What other things are you expected to know?\n",
    "\n",
    "#### Data Analyst/Data Scientist\n",
    "- Mostly will want to know about the data-structures that are avaialable to you, how to query them, and the more you know about doing so efficiently the easier your life will be. Sometimes you will have to know a little bit more about moving the data ad-hoc, but if you find that you do something often it's in your best interest to learn that as well.\n",
    "- Tools may include Python, R, and a few flavors of SQL (Postgres, MySQL, Oracle, BigQuery, Hive, etc.) to pull data, as well as potentially a NoSQL framework depending on what company needs are. You'll also likely know a litany of analytics libraries within those languages, data and visualization tools like Tableau/PowerBI, and Front-end (Javascript, D3JS, HTML, CSS, ect.)\n",
    "\n",
    "#### Data Engineer\n",
    "- You'll likely know more about where data is stored, how often it is updated, what tools can be used to perform the most efficient ETL with this data, and may be writing to databases at some rate. These are the people that will understand the data scientists/data analysts needs and be able to productionalize workflows so that this data is delivered efficiently and with the cadence that it is needed.\n",
    "- Tools may include SQL and NoSQL languages, some ETL engines/workflow management such as Apache Airflow, some scripting language, and virtualization and big-data tools/dbs like Apache Druid, Apache Kafka, Docker, etc.\n",
    "- Brief description of some different ETL tools (https://www.softwaretestinghelp.com/best-etl-tools/) there are many...\n",
    "\n",
    "#### Database Architect/\"Database Owner\"\n",
    "- Depending on your organization this role will look very different, but overall, this is the person with the answers about a certain/all of the databases. They know where everything is, how it is structured, the thought process that went into structuring it that way, a lot of the logic that the database is performing as the data is saved and moved, how well the database(s) used by the company can scale/perform under load, etc. These people can speak to how accurate the underlying data is, where it is coming from, and how it is being processed, they know it all.\n",
    "- DB/Solutions architects will know an exceptional amount about the underlying databases that are being used, the tools that are being used to connect them, and are likely experts in Docker, the command line, whatever db the team is using, the command line, linux/server programming. They are also likely going to be the ones with the keys and payment info for AWS, Google Cloud, Azure, wherever the data is stored, and likely have several certificates and credentials to show for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some other Quick hits...\n",
    "\n",
    "- \"How do we interact with this?\" - Depeneding on the different use-cases, you may be in a SQL tool, command line, or a browser window. No matter where a database is stored, think about it as if it is data that exists somewhere, and you are opening a connection to it. (The analogy I've heard is that you have to pick up the phone and talk through it to have a conversation, you'd imagine the database as being on the other side of that call sending information back to you, somewhat like an API).\n",
    "- Optimization of databases within a company is something that you can build an entire career on, and the way to optimize how these systems all work together takes a lot of knowledge about the limitations as well as the strong points of all of the various options out there, don't worry, this will not necessarily be your job, but it never hurts to know more about the systems you're working with to aggregate and query the data as well as how it's processed.\n",
    "- \"How do these databases make connections?\" As you build up code with Python or different frameworks, you may very well be someone who is helping to connect several databases to do different things (such as building up a reporting system to wake at 5:00, compile some data from 2-3 different locations, and then chew through it and send out a report by 9:15.\n",
    "- (con't) There are several helpful ETL frameworks out there to make this more organized, but in several cases an etl tool will enable you to run a script that you wrote that picked up and used several pieces of data from different places. One example I've heard to be very successful is Apache Airflow (https://airflow.apache.org/docs/stable/concepts.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demoing some database tools\n",
    "\n",
    "#### Mysql (https://www.mysql.com/products/workbench/)\n",
    "- Brief look, want to just see how closely this resembles pgadmin\n",
    "- Want to highlight that although there are differences between all of the different query editors/sql tools, there are lots of similarities as well.\n",
    "- Will briefly take a look at a sql script to discuss how a database can be built from a sql file.\n",
    "\n",
    "#### PGAdmin (https://www.pgadmin.org/)\n",
    "- This is the one that we learn in class and are going to be used in the near future\n",
    "- Is being handled by the same organization that is responsible for Postgres, so it is very closely integrated and is a first-party tool, rather than one that can be used on multiple databases. Most databases will have a vanilla DB Manager like this.\n",
    "- SQL tools released like this will often contain most of the more frequently-used tools, but will not necessarily have every single tool available\n",
    "- Querying, loading data from csv, etc.\n",
    "\n",
    "#### DBeaver (https://dbeaver.io/)\n",
    "- Upon hearing the recommendation from a former instructor here, I've been using DBeaver exclusively for ~8 months for my database needs.\n",
    "- DBeaver is built in a way that allows you to query several databases from it, there are tools like this out there that will be a \"universal\" sort of front-end that you can plug into all sorts of datasources.\n",
    "- These tools also can contain a little bit more than the vanilla editors like PGAdmin out of the box such as built-in support for ER diagrams.\n",
    "- Brief discussion on databases/database types that can plug into DBeaver\n",
    "- Working with a SQLite file\n",
    "\n",
    "#### Google BigQuery (https://cloud.google.com/bigquery/docs/quickstarts/quickstart-web-ui)\n",
    "- NOTE: Unless otherwise specified, every BigQuery query costs money! So as you work with it as a hobby, make sure to use small datasets OR get a job where BigQuery is the data warehouse of choice.\n",
    "- Wanted to come back to this following our discussion last week on BigQuery.\n",
    "- Just to show that whether you are hitting a small database built by you, or a massive one that lives in BQ, there are lots of similarities to the experience.\n",
    "- Again, a lot of this is about exposure to different platforms and realizing that despite all of the differences between them, you should be recognizing the similarities and doing your best to connect them to your existing knowledge. You'll find that you can familiarize yourself with a lot of these tools more quickly than you'd expect.\n",
    "- Once you're familiarized, take the time to learn more and become an expert at the technology you like the most."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
